{
  "comments": [
    {
      "key": {
        "uuid": "5a7ca5a3_53db401b",
        "filename": "docs/design/specs/High-Priority-Traffic-Path.rst",
        "patchSetId": 3
      },
      "lineNbr": 151,
      "author": {
        "id": 1401
      },
      "writtenOn": "2016-07-01T10:50:08Z",
      "side": 1,
      "message": "What do we mean by controlling an external application.\n\nAlso, aren\u0027t we going to utilize flow rules to match packets and steer them to queues interfaces that have the given meta data? This would be the traffic engineering part of it.",
      "revId": "c8fcad9a535bd5980d33d5ea772f67d988879bc9",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "5a7ca5a3_139628f1",
        "filename": "docs/design/specs/High-Priority-Traffic-Path.rst",
        "patchSetId": 3
      },
      "lineNbr": 151,
      "author": {
        "id": 50
      },
      "writtenOn": "2016-07-01T13:55:01Z",
      "side": 1,
      "message": "If you mean, integrate this into the flow classification interface of ovs (e.g. ofctl), then I think that would be the ideal interface.  However, when I tried to do that, I realised that it would be really tricky to implement. I believe we would need to have a seperate flow classification entity that classifies much earlier in the pipeline and also more lightweight as we dont want to spend a load of cycles classifying a low priority packet before we even look at a high priority packet. However, if you can think of a way to do this, I would love to hear your suggestion as this is the point of writing all this down to elicit this type of feedback.",
      "parentUuid": "5a7ca5a3_53db401b",
      "revId": "c8fcad9a535bd5980d33d5ea772f67d988879bc9",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "5a7ca5a3_4569318a",
        "filename": "docs/design/specs/High-Priority-Traffic-Path.rst",
        "patchSetId": 3
      },
      "lineNbr": 151,
      "author": {
        "id": 385
      },
      "writtenOn": "2016-07-04T13:49:32Z",
      "side": 1,
      "message": "So (brainstorming) if the early classifier only looked at packet marking(s), it could prioritize the subsequent processing, but that assumes a queue between the two processing stages.",
      "parentUuid": "5a7ca5a3_139628f1",
      "revId": "c8fcad9a535bd5980d33d5ea772f67d988879bc9",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "5a7ca5a3_18e5e0a7",
        "filename": "docs/design/specs/High-Priority-Traffic-Path.rst",
        "patchSetId": 3
      },
      "lineNbr": 151,
      "author": {
        "id": 50
      },
      "writtenOn": "2016-07-05T12:02:11Z",
      "side": 1,
      "message": "Yes we would need a queue in this case\n\nThe code flow (at a high level) in OVS is \n\nflow extraction -\u003e table lookup to retrieve actions -\u003e action execute\n\nIf we were to do some reordering based on the regular flow classification path, we would need to insert it after the table lookup. At that stage we would have executed the majority of the code path which would probably negate the benefit of this addition. Is there another way we could do this using the regular flow classification?",
      "parentUuid": "5a7ca5a3_4569318a",
      "revId": "c8fcad9a535bd5980d33d5ea772f67d988879bc9",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "5a7ca5a3_732f49a2",
        "filename": "docs/design/specs/High-Priority-Traffic-Path.rst",
        "patchSetId": 3
      },
      "lineNbr": 151,
      "author": {
        "id": 1401
      },
      "writtenOn": "2016-07-14T11:12:21Z",
      "side": 1,
      "message": "I have been looking at Open Flow 1.5. I think OF 1.5 has what is needed to support QoS with flows. OF now has support for queues in a port, egress tables and packet type aware pipeline processing. OF 1.5 pg 14, section 5.1 on page 19, Figure 3, Section 7.3.5.8, 5.8 Actions, Page 28 and Appendix B18.\n\nDoing QoS with flows would provide a mechanism for looking at an ingress packet moving it to a separate higher priority pipeline and then on egress doing a set_queue action to forward it. These new mechanism in addition to match on PCP and DSCP would provide all the bits to implement QoS.",
      "parentUuid": "5a7ca5a3_18e5e0a7",
      "revId": "c8fcad9a535bd5980d33d5ea772f67d988879bc9",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1a76adc5_bc3085e9",
        "filename": "docs/design/specs/High-Priority-Traffic-Path.rst",
        "patchSetId": 3
      },
      "lineNbr": 151,
      "author": {
        "id": 50
      },
      "writtenOn": "2016-07-19T13:31:55Z",
      "side": 1,
      "message": "Hi Tom, \n\nI had a good read about this. I think the last time I read the OF spec was 1.3 and some things have changed, great to have a look again.\n\nIn section 7.3.5.8, it states that \"Packet scheduling using queues is not defined by this specification and is switch dependent, in particular no priority between queue IDs\nis assumed.\" Which for me, indicates that scheduling between queues in egress is not possible with this mechanism according to the spec. Also, egress tables dont seem to be supported in OVS. However, we could implement these things if required. Could you describe what the pipeline would look like in terms of ovs-ofctl commands?\n\nEven with this, I cant get around the fact that the dataplane processes packets in bursts of 32. So, for example, if I have two bursts like so (H \u003d high priority, L\u003dlow priority):\n\nburst 0: HLHLHLHLHLHLH...HLHLHL\nburst 1: HHHHHHHHHHHHH...HHHHHH\n\nI would expect the traffic to be recieved like this\nHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHLLLLLLL\n\nbut because we process in batches, we would actually get\nHHHHHHHHHHLLLLLLLLLLLLLHHHHHHHHHHHHHHHHHHHH\n\nTherefore we need to queue somewhere. If we use Openflow, we will enqueue the packet as part of the action execution so we have to spend a lot of cycles processing the packet before we enqueue it. To me, this does not seem like the behaviour that would be expected.",
      "parentUuid": "5a7ca5a3_732f49a2",
      "revId": "c8fcad9a535bd5980d33d5ea772f67d988879bc9",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1a76adc5_2e418d39",
        "filename": "docs/design/specs/High-Priority-Traffic-Path.rst",
        "patchSetId": 3
      },
      "lineNbr": 151,
      "author": {
        "id": 1401
      },
      "writtenOn": "2016-07-28T13:41:26Z",
      "side": 1,
      "message": "I think that statement in 7.3.5.8 is only stating that packet scheduling implementation is the decision of the switch. However I think 1.5 clearly provides the framework for implementing queues with scheduling. Openflow is the specification of the control path and switch behavior, not switch implementation.\n\nI agree that we need actual queues implemented and I assumed perhaps wrongly that it could that be in dpdk data path. \n\n I thought it was architecturally cleaner to control the queues via open flow then with ovsdb metadata. This is now possible in 1.5 because of the addition of queue IDs and egress tables. Since 1.5 now supports egress tables, the initial action on the ingress table would direct the queue differentiated traffic toward the egress table that would separate the queues. The action on the egress table would direct a packet toward the output queue.\n\nAs for the bursts and mixed traffic per queue. I think this is the same problem that ghost-user multi-queue has and maybe could be solved the same way.",
      "parentUuid": "1a76adc5_bc3085e9",
      "revId": "c8fcad9a535bd5980d33d5ea772f67d988879bc9",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    }
  ]
}