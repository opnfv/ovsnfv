{
  "comments": [
    {
      "key": {
        "uuid": "5a7ca5a3_b054f754",
        "filename": "docs/design/specs/High-Priority-Traffic-Path.rst",
        "patchSetId": 4
      },
      "lineNbr": 151,
      "author": {
        "id": 385
      },
      "writtenOn": "2016-07-13T23:20:19Z",
      "side": 1,
      "message": "flow extraction -\u003e table lookup to retrieve actions -\u003e action execute\nExamination of Packet marking could take place before the rest of flow extraction. But that requires a queue at the start of this chain of processes.",
      "revId": "aeadadbbbd2403044572d0a7d6980132033739ba",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "5a7ca5a3_4664c9b8",
        "filename": "docs/design/specs/High-Priority-Traffic-Path.rst",
        "patchSetId": 4
      },
      "lineNbr": 151,
      "author": {
        "id": 50
      },
      "writtenOn": "2016-08-05T08:11:42Z",
      "side": 1,
      "message": "Yes, agreed. Do you not think this is acceptable?",
      "parentUuid": "5a7ca5a3_b054f754",
      "revId": "aeadadbbbd2403044572d0a7d6980132033739ba",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1a76adc5_5d86f4ba",
        "filename": "docs/design/specs/High-Priority-Traffic-Path.rst",
        "patchSetId": 4
      },
      "lineNbr": 151,
      "author": {
        "id": 385
      },
      "writtenOn": "2016-08-06T17:58:23Z",
      "side": 1,
      "message": "Thinking back to the slides I used months ago, and looking at the NIC batch processing sequence of HLHLHLHLHLHL HHHHH.... , I think that two parallel queues to sort between the H and L frames, and a queue management that serves the H first, then serves the L queue until the next batch arrives. The H frames would be served again when the next burst arrives, but there has to be a minimum service time for the L queue.  So, we see a sequence something like this:  HHHHHHHHH LLLL HHHHHHHHH LLLL",
      "parentUuid": "5a7ca5a3_4664c9b8",
      "revId": "aeadadbbbd2403044572d0a7d6980132033739ba",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1a76adc5_3820e648",
        "filename": "docs/design/specs/High-Priority-Traffic-Path.rst",
        "patchSetId": 4
      },
      "lineNbr": 151,
      "author": {
        "id": 50
      },
      "writtenOn": "2016-08-08T08:02:54Z",
      "side": 1,
      "message": "I hadn\u0027t though about minimal service time. I presume this would need to be configurable?",
      "parentUuid": "1a76adc5_5d86f4ba",
      "revId": "aeadadbbbd2403044572d0a7d6980132033739ba",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1a76adc5_d352f512",
        "filename": "docs/design/specs/High-Priority-Traffic-Path.rst",
        "patchSetId": 4
      },
      "lineNbr": 151,
      "author": {
        "id": 385
      },
      "writtenOn": "2016-08-08T15:36:12Z",
      "side": 1,
      "message": "Configurable, yes. In a two-class system, one service time sets the minimum for the other class.  If either class does not have sufficient frames to fill the minimum service time,\nthe other class should be able to send in the underutilized time.  The good news is that with batch delivery of all frames, we get to look ahead, but we may not be able to predict the exact processing times in the switch (that seems to be where the fun starts, IOW, if we can always switch the full 32 frame batch we haven\u0027t established a need for priority processing other than to re-order the frames...).",
      "parentUuid": "1a76adc5_3820e648",
      "revId": "aeadadbbbd2403044572d0a7d6980132033739ba",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    }
  ]
}